{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QzBnS-CNo_ww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de35dda-5664-4bfb-ac33-c15598b1e9a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h5py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zypgdcbe_ep_",
        "outputId": "b84dd2c3-4857-4720-d534-e77a677658d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmdhxwAWVF9P"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import sklearn.model_selection\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import io\n",
        "import imageio\n",
        "import os\n",
        "import re\n",
        "import torch\n",
        "\n",
        "# Modify the path to point to the appropriate location in Google Colab\n",
        "#data_folder = \"/content/drive/My Drive/gnr\"\n",
        "\n",
        "def get_device(ordinal):\n",
        "    if ordinal < 0:\n",
        "        print(\"Computation on CPU\")\n",
        "        device = torch.device('cpu')\n",
        "    else:\n",
        "        print(\"Computation on CUDA GPU device {}\".format(ordinal))\n",
        "        device = torch.device('cuda:{}'.format(ordinal))\n",
        "    return device\n",
        "\n",
        "def seed_worker(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "import h5py\n",
        "\n",
        "def open_file(dataset):\n",
        "    ext = dataset.split('.')[-1].lower()\n",
        "    if ext == '.mat':\n",
        "        return h5py.File(dataset, 'r')  # Replace io.loadmat with h5py.File\n",
        "    elif ext == '.tif' or ext == '.tiff':\n",
        "        return imageio.imread(dataset)\n",
        "\n",
        "def convert_to_color_(arr_2d, palette=None):\n",
        "    arr_3d = np.zeros((arr_2d.shape[0], arr_2d.shape[1], 3), dtype=np.uint8)\n",
        "    if palette is None:\n",
        "        raise Exception(\"Unknown color palette\")\n",
        "\n",
        "    for c, i in palette.items():\n",
        "        m = arr_2d == c\n",
        "        arr_3d[m] = i\n",
        "\n",
        "    return arr_3d\n",
        "\n",
        "def convert_from_color_(arr_3d, palette=None):\n",
        "    if palette is None:\n",
        "        raise Exception(\"Unknown color palette\")\n",
        "\n",
        "    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.uint8)\n",
        "\n",
        "    for c, i in palette.items():\n",
        "        m = np.all(arr_3d == np.array(c).reshape(1, 1, 3), axis=2)\n",
        "        arr_2d[m] = i\n",
        "\n",
        "    return arr_2d\n",
        "\n",
        "# Define other functions similarly, modifying paths as necessary\n",
        "\n",
        "\n",
        "def display_predictions(pred, vis, gt=None, caption=\"\"):\n",
        "    if gt is None:\n",
        "        vis.images([np.transpose(pred, (2, 0, 1))],\n",
        "                    opts={'caption': caption})\n",
        "    else:\n",
        "        vis.images([np.transpose(pred, (2, 0, 1)),\n",
        "                    np.transpose(gt, (2, 0, 1))],\n",
        "                    nrow=2,\n",
        "                    opts={'caption': caption})\n",
        "\n",
        "def display_dataset(img, gt, bands, labels, palette, vis):\n",
        "    \"\"\"Display the specified dataset.\n",
        "\n",
        "    Args:\n",
        "        img: 3D hyperspectral image\n",
        "        gt: 2D array labels\n",
        "        bands: tuple of RGB bands to select\n",
        "        labels: list of label class names\n",
        "        palette: dict of colors\n",
        "        display (optional): type of display, if any\n",
        "\n",
        "    \"\"\"\n",
        "    print(\"Image has dimensions {}x{} and {} channels\".format(*img.shape))\n",
        "    rgb = spectral.get_rgb(img, bands)\n",
        "    rgb /= np.max(rgb)\n",
        "    rgb = np.asarray(255 * rgb, dtype='uint8')\n",
        "\n",
        "    # Display the RGB composite image\n",
        "    caption = \"RGB (bands {}, {}, {})\".format(*bands)\n",
        "    # send to visdom server\n",
        "    vis.images([np.transpose(rgb, (2, 0, 1))],\n",
        "                opts={'caption': caption})\n",
        "\n",
        "def explore_spectrums(img, complete_gt, class_names, vis,\n",
        "                      ignored_labels=None):\n",
        "    \"\"\"Plot sampled spectrums with mean + std for each class.\n",
        "\n",
        "    Args:\n",
        "        img: 3D hyperspectral image\n",
        "        complete_gt: 2D array of labels\n",
        "        class_names: list of class names\n",
        "        ignored_labels (optional): list of labels to ignore\n",
        "        vis : Visdom display\n",
        "    Returns:\n",
        "        mean_spectrums: dict of mean spectrum by class\n",
        "\n",
        "    \"\"\"\n",
        "    mean_spectrums = {}\n",
        "    for c in np.unique(complete_gt):\n",
        "        if c in ignored_labels:\n",
        "            continue\n",
        "        mask = complete_gt == c\n",
        "        class_spectrums = img[mask].reshape(-1, img.shape[-1])\n",
        "        step = max(1, class_spectrums.shape[0] // 100)\n",
        "        fig = plt.figure()\n",
        "        plt.title(class_names[c])\n",
        "        # Sample and plot spectrums from the selected class\n",
        "        for spectrum in class_spectrums[::step, :]:\n",
        "            plt.plot(spectrum, alpha=0.25)\n",
        "        mean_spectrum = np.mean(class_spectrums, axis=0)\n",
        "        std_spectrum = np.std(class_spectrums, axis=0)\n",
        "        lower_spectrum = np.maximum(0, mean_spectrum - std_spectrum)\n",
        "        higher_spectrum = mean_spectrum + std_spectrum\n",
        "\n",
        "        # Plot the mean spectrum with thickness based on std\n",
        "        plt.fill_between(range(len(mean_spectrum)), lower_spectrum,\n",
        "                         higher_spectrum, color=\"#3F5D7D\")\n",
        "        plt.plot(mean_spectrum, alpha=1, color=\"#FFFFFF\", lw=2)\n",
        "        vis.matplot(plt)\n",
        "        mean_spectrums[class_names[c]] = mean_spectrum\n",
        "    return mean_spectrums\n",
        "\n",
        "\n",
        "def plot_spectrums(spectrums, vis, title=\"\"):\n",
        "    \"\"\"Plot the specified dictionary of spectrums.\n",
        "\n",
        "    Args:\n",
        "        spectrums: dictionary (name -> spectrum) of spectrums to plot\n",
        "        vis: Visdom display\n",
        "    \"\"\"\n",
        "    win = None\n",
        "    for k, v in spectrums.items():\n",
        "        n_bands = len(v)\n",
        "        update = None if win is None else 'append'\n",
        "        win = vis.line(X=np.arange(n_bands), Y=v, name=k, win=win, update=update,\n",
        "                       opts={'title': title})\n",
        "\n",
        "\n",
        "def build_dataset(mat, gt, ignored_labels=None):\n",
        "    \"\"\"Create a list of training samples based on an image and a mask.\n",
        "\n",
        "    Args:\n",
        "        mat: 3D hyperspectral matrix to extract the spectrums from\n",
        "        gt: 2D ground truth\n",
        "        ignored_labels (optional): list of classes to ignore, e.g. 0 to remove\n",
        "        unlabeled pixels\n",
        "        return_indices (optional): bool set to True to return the indices of\n",
        "        the chosen samples\n",
        "\n",
        "    \"\"\"\n",
        "    samples = []\n",
        "    labels = []\n",
        "    # Check that image and ground truth have the same 2D dimensions\n",
        "    assert mat.shape[:2] == gt.shape[:2]\n",
        "\n",
        "    for label in np.unique(gt):\n",
        "        if label in ignored_labels:\n",
        "            continue\n",
        "        else:\n",
        "            indices = np.nonzero(gt == label)\n",
        "            samples += list(mat[indices])\n",
        "            labels += len(indices[0]) * [label]\n",
        "    return np.asarray(samples), np.asarray(labels)\n",
        "\n",
        "\n",
        "def get_random_pos(img, window_shape):\n",
        "    \"\"\" Return the corners of a random window in the input image\n",
        "\n",
        "    Args:\n",
        "        img: 2D (or more) image, e.g. RGB or grayscale image\n",
        "        window_shape: (width, height) tuple of the window\n",
        "\n",
        "    Returns:\n",
        "        xmin, xmax, ymin, ymax: tuple of the corners of the window\n",
        "\n",
        "    \"\"\"\n",
        "    w, h = window_shape\n",
        "    W, H = img.shape[:2]\n",
        "    x1 = random.randint(0, W - w - 1)\n",
        "    x2 = x1 + w\n",
        "    y1 = random.randint(0, H - h - 1)\n",
        "    y2 = y1 + h\n",
        "    return x1, x2, y1, y2\n",
        "\n",
        "\n",
        "def sliding_window(image, step=10, window_size=(20, 20), with_data=True):\n",
        "    \"\"\"Sliding window generator over an input image.\n",
        "\n",
        "    Args:\n",
        "        image: 2D+ image to slide the window on, e.g. RGB or hyperspectral\n",
        "        step: int stride of the sliding window\n",
        "        window_size: int tuple, width and height of the window\n",
        "        with_data (optional): bool set to True to return both the data and the\n",
        "        corner indices\n",
        "    Yields:\n",
        "        ([data], x, y, w, h) where x and y are the top-left corner of the\n",
        "        window, (w,h) the window size\n",
        "\n",
        "    \"\"\"\n",
        "    # slide a window across the image\n",
        "    w, h = window_size\n",
        "    W, H = image.shape[:2]\n",
        "    offset_w = (W - w) % step\n",
        "    offset_h = (H - h) % step\n",
        "    for x in range(0, W - w + offset_w, step):\n",
        "        if x + w > W:\n",
        "            x = W - w\n",
        "        for y in range(0, H - h + offset_h, step):\n",
        "            if y + h > H:\n",
        "                y = H - h\n",
        "            if with_data:\n",
        "                yield image[x:x + w, y:y + h], x, y, w, h\n",
        "            else:\n",
        "                yield x, y, w, h\n",
        "\n",
        "\n",
        "def count_sliding_window(top, step=10, window_size=(20, 20)):\n",
        "    \"\"\" Count the number of windows in an image.\n",
        "\n",
        "    Args:\n",
        "        image: 2D+ image to slide the window on, e.g. RGB or hyperspectral, ...\n",
        "        step: int stride of the sliding window\n",
        "        window_size: int tuple, width and height of the window\n",
        "    Returns:\n",
        "        int number of windows\n",
        "    \"\"\"\n",
        "    sw = sliding_window(top, step, window_size, with_data=False)\n",
        "    return sum(1 for _ in sw)\n",
        "\n",
        "\n",
        "def grouper(n, iterable):\n",
        "    \"\"\" Browse an iterable by grouping n elements by n elements.\n",
        "\n",
        "    Args:\n",
        "        n: int, size of the groups\n",
        "        iterable: the iterable to Browse\n",
        "    Yields:\n",
        "        chunk of n elements from the iterable\n",
        "\n",
        "    \"\"\"\n",
        "    it = iter(iterable)\n",
        "    while True:\n",
        "        chunk = tuple(itertools.islice(it, n))\n",
        "        if not chunk:\n",
        "            return\n",
        "        yield chunk\n",
        "\n",
        "\n",
        "def metrics(prediction, target, ignored_labels=[], n_classes=None):\n",
        "    \"\"\"Compute and print metrics (accuracy, confusion matrix and F1 scores).\n",
        "\n",
        "    Args:\n",
        "        prediction: list of predicted labels\n",
        "        target: list of target labels\n",
        "        ignored_labels (optional): list of labels to ignore, e.g. 0 for undef\n",
        "        n_classes (optional): number of classes, max(target) by default\n",
        "    Returns:\n",
        "        accuracy, F1 score by class, confusion matrix\n",
        "    \"\"\"\n",
        "    ignored_mask = np.zeros(target.shape[:2], dtype=np.bool)\n",
        "    for l in ignored_labels:\n",
        "        ignored_mask[target == l] = True\n",
        "    ignored_mask = ~ignored_mask\n",
        "    #target = target[ignored_mask] -1\n",
        "    # target = target[ignored_mask]\n",
        "    # prediction = prediction[ignored_mask]\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    n_classes = np.max(target) + 1 if n_classes is None else n_classes\n",
        "\n",
        "    cm = confusion_matrix(\n",
        "        target,\n",
        "        prediction,\n",
        "        labels=range(n_classes))\n",
        "\n",
        "    results[\"Confusion_matrix\"] = cm\n",
        "\n",
        "    FP = cm.sum(axis=0) - np.diag(cm)\n",
        "    FN = cm.sum(axis=1) - np.diag(cm)\n",
        "    TP = np.diag(cm)\n",
        "    TN = cm.sum() - (FP + FN + TP)\n",
        "\n",
        "    FP = FP.astype(float)\n",
        "    FN = FN.astype(float)\n",
        "    TP = TP.astype(float)\n",
        "    TN = TN.astype(float)\n",
        "    # Sensitivity, hit rate, recall, or true positive rate\n",
        "    TPR = TP/(TP+FN)\n",
        "    results[\"TPR\"] = TPR\n",
        "    # Compute global accuracy\n",
        "    total = np.sum(cm)\n",
        "    accuracy = sum([cm[x][x] for x in range(len(cm))])\n",
        "    accuracy *= 100 / float(total)\n",
        "\n",
        "    results[\"Accuracy\"] = accuracy\n",
        "\n",
        "    # Compute F1 score\n",
        "    F1scores = np.zeros(len(cm))\n",
        "    for i in range(len(cm)):\n",
        "        try:\n",
        "            F1 = 2 * cm[i, i] / (np.sum(cm[i, :]) + np.sum(cm[:, i]))\n",
        "        except ZeroDivisionError:\n",
        "            F1 = 0.\n",
        "        F1scores[i] = F1\n",
        "\n",
        "    results[\"F1_scores\"] = F1scores\n",
        "\n",
        "    # Compute kappa coefficient\n",
        "    pa = np.trace(cm) / float(total)\n",
        "    pe = np.sum(np.sum(cm, axis=0) * np.sum(cm, axis=1)) / \\\n",
        "        float(total * total)\n",
        "    kappa = (pa - pe) / (1 - pe)\n",
        "    results[\"Kappa\"] = kappa\n",
        "\n",
        "    results[\"prediction\"] = prediction\n",
        "    results[\"label\"] = target\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def show_results(results, vis, label_values=None, agregated=False):\n",
        "    text = \"\"\n",
        "\n",
        "    if agregated:\n",
        "        accuracies = [r[\"Accuracy\"] for r in results]\n",
        "        kappas = [r[\"Kappa\"] for r in results]\n",
        "        F1_scores = [r[\"F1_scores\"] for r in results]\n",
        "\n",
        "        F1_scores_mean = np.mean(F1_scores, axis=0)\n",
        "        F1_scores_std = np.std(F1_scores, axis=0)\n",
        "        cm = np.mean([r[\"Confusion_matrix\"] for r in results], axis=0)\n",
        "        text += \"Agregated results :\\n\"\n",
        "    else:\n",
        "        cm = results[\"Confusion_matrix\"]\n",
        "        accuracy = results[\"Accuracy\"]\n",
        "        F1scores = results[\"F1_scores\"]\n",
        "        kappa = results[\"Kappa\"]\n",
        "\n",
        "    #label_values = label_values[1:]\n",
        "    vis.heatmap(cm, opts={'title': \"Confusion_matrix\",\n",
        "                          'marginbottom': 150,\n",
        "                          'marginleft': 150,\n",
        "                          'width': 500,\n",
        "                          'height': 500,\n",
        "                          'rownames': label_values, 'columnnames': label_values})\n",
        "    text += \"Confusion_matrix :\\n\"\n",
        "    text += str(cm)\n",
        "    text += \"---\\n\"\n",
        "\n",
        "    if agregated:\n",
        "        text += (\"Accuracy: {:.03f} +- {:.03f}\\n\".format(np.mean(accuracies),\n",
        "                                                         np.std(accuracies)))\n",
        "    else:\n",
        "        text += \"Accuracy : {:.03f}%\\n\".format(accuracy)\n",
        "    text += \"---\\n\"\n",
        "\n",
        "    text += \"F1_scores :\\n\"\n",
        "    if agregated:\n",
        "        for label, score, std in zip(label_values, F1_scores_mean,\n",
        "                                     F1_scores_std):\n",
        "            text += \"\\t{}: {:.03f} +- {:.03f}\\n\".format(label, score, std)\n",
        "    else:\n",
        "        for label, score in zip(label_values, F1scores):\n",
        "            text += \"\\t{}: {:.03f}\\n\".format(label, score)\n",
        "    text += \"---\\n\"\n",
        "\n",
        "    if agregated:\n",
        "        text += (\"Kappa: {:.03f} +- {:.03f}\\n\".format(np.mean(kappas),\n",
        "                                                      np.std(kappas)))\n",
        "    else:\n",
        "        text += \"Kappa: {:.03f}\\n\".format(kappa)\n",
        "\n",
        "    vis.text(text.replace('\\n', '<br/>'))\n",
        "    print(text)\n",
        "\n",
        "\n",
        "def sample_gt(gt, train_size, mode='random'):\n",
        "    \"\"\"Extract a fixed percentage of samples from an array of labels.\n",
        "\n",
        "    Args:\n",
        "        gt: a 2D array of int labels\n",
        "        percentage: [0, 1] float\n",
        "    Returns:\n",
        "        train_gt, test_gt: 2D arrays of int labels\n",
        "\n",
        "    \"\"\"\n",
        "    indices = np.nonzero(gt)\n",
        "    X = list(zip(*indices)) # x,y features\n",
        "    y = gt[indices].ravel() # classes\n",
        "    train_gt = np.zeros_like(gt)\n",
        "    test_gt = np.zeros_like(gt)\n",
        "    if train_size > 1:\n",
        "       train_size = int(train_size)\n",
        "    train_label = []\n",
        "    test_label = []\n",
        "    if mode == 'random':\n",
        "        if train_size == 1:\n",
        "            random.shuffle(X)\n",
        "            train_indices = [list(t) for t in zip(*X)]\n",
        "            [train_label.append(i) for i in gt[tuple(train_indices)]]\n",
        "            train_set = np.column_stack((train_indices[0],train_indices[1],train_label))\n",
        "            train_gt[tuple(train_indices)] = gt[tuple(train_indices)]\n",
        "            test_gt = []\n",
        "            test_set = []\n",
        "        else:\n",
        "            train_indices, test_indices = sklearn.model_selection.train_test_split(X, train_size=train_size, stratify=y, random_state=23)\n",
        "            train_indices = [list(t) for t in zip(*train_indices)]\n",
        "            test_indices = [list(t) for t in zip(*test_indices)]\n",
        "            train_gt[tuple(train_indices)] = gt[tuple(train_indices)]\n",
        "            test_gt[tuple(test_indices)] = gt[tuple(test_indices)]\n",
        "\n",
        "            [train_label.append(i) for i in gt[tuple(train_indices)]]\n",
        "            train_set = np.column_stack((train_indices[0],train_indices[1],train_label))\n",
        "            [test_label.append(i) for i in gt[tuple(test_indices)]]\n",
        "            test_set = np.column_stack((test_indices[0],test_indices[1],test_label))\n",
        "\n",
        "    elif mode == 'disjoint':\n",
        "        train_gt = np.copy(gt)\n",
        "        test_gt = np.copy(gt)\n",
        "        for c in np.unique(gt):\n",
        "            mask = gt == c\n",
        "            for x in range(gt.shape[0]):\n",
        "                first_half_count = np.count_nonzero(mask[:x, :])\n",
        "                second_half_count = np.count_nonzero(mask[x:, :])\n",
        "                try:\n",
        "                    ratio = first_half_count / second_half_count\n",
        "                    if ratio > 0.9 * train_size and ratio < 1.1 * train_size:\n",
        "                        break\n",
        "                except ZeroDivisionError:\n",
        "                    continue\n",
        "            mask[:x, :] = 0\n",
        "            train_gt[mask] = 0\n",
        "\n",
        "        test_gt[train_gt > 0] = 0\n",
        "    else:\n",
        "        raise ValueError(\"{} sampling is not implemented yet.\".format(mode))\n",
        "    return train_gt, test_gt, train_set, test_set\n",
        "\n",
        "\n",
        "def sample_gt_fixed(gt, train_size_list, mode='random'):\n",
        "    \"\"\"Extract a fixed percentage of samples from an array of labels.\n",
        "\n",
        "    Args:\n",
        "        gt: a 2D array of int labels\n",
        "        percentage: [0, 1] float\n",
        "    Returns:\n",
        "        train_gt, test_gt: 2D arrays of int labels\n",
        "\n",
        "    \"\"\"\n",
        "    indices = np.nonzero(gt)\n",
        "    X = list(zip(*indices))  # x,y features\n",
        "    y = gt[indices].ravel()  # classes\n",
        "    train_gt = np.zeros_like(gt)\n",
        "    test_gt = np.zeros_like(gt)\n",
        "\n",
        "    train_label = []\n",
        "    test_label = []\n",
        "    print(\"Sampling {} with train size = {}\".format(mode, train_size_list))\n",
        "    train_indices, test_indices = [], []\n",
        "    train_label = []\n",
        "    test_label = []\n",
        "    for c in np.unique(gt):\n",
        "        if c == 0:\n",
        "            continue\n",
        "        indices = np.nonzero(gt == c)\n",
        "        X = list(zip(*indices))  # x,y features\n",
        "\n",
        "        train, test = sklearn.model_selection.train_test_split(\n",
        "            X, train_size=train_size_list[c-1], random_state=23)\n",
        "        train_indices += train\n",
        "        test_indices += test\n",
        "    train_indices = [list(t) for t in zip(*train_indices)]\n",
        "    test_indices = [list(t) for t in zip(*test_indices)]\n",
        "    train_gt[train_indices] = gt[train_indices]\n",
        "    test_gt[test_indices] = gt[test_indices]\n",
        "\n",
        "    [train_label.append(i) for i in gt[train_indices]]\n",
        "    train_set = np.column_stack(\n",
        "        (train_indices[0], train_indices[1], train_label))\n",
        "    [test_label.append(i) for i in gt[test_indices]]\n",
        "    test_set = np.column_stack((test_indices[0], test_indices[1], test_label))\n",
        "\n",
        "    return train_gt, test_gt, train_set, test_set\n",
        "\n",
        "def compute_imf_weights(ground_truth, n_classes=None, ignored_classes=[]):\n",
        "    \"\"\" Compute inverse median frequency weights for class balancing.\n",
        "\n",
        "    For each class i, it computes its frequency f_i, i.e the ratio between\n",
        "    the number of pixels from class i and the total number of pixels.\n",
        "\n",
        "    Then, it computes the median m of all frequencies. For each class the\n",
        "    associated weight is m/f_i.\n",
        "\n",
        "    Args:\n",
        "        ground_truth: the annotations array\n",
        "        n_classes: number of classes (optional, defaults to max(ground_truth))\n",
        "        ignored_classes: id of classes to ignore (optional)\n",
        "    Returns:\n",
        "        numpy array with the IMF coefficients\n",
        "    \"\"\"\n",
        "    n_classes = np.max(ground_truth) if n_classes is None else n_classes\n",
        "    weights = np.zeros(n_classes)\n",
        "    frequencies = np.zeros(n_classes)\n",
        "\n",
        "    for c in range(0, n_classes):\n",
        "        if c in ignored_classes:\n",
        "            continue\n",
        "        frequencies[c] = np.count_nonzero(ground_truth == c)\n",
        "\n",
        "    # Normalize the pixel counts to obtain frequencies\n",
        "    frequencies /= np.sum(frequencies)\n",
        "    # Obtain the median on non-zero frequencies\n",
        "    idx = np.nonzero(frequencies)\n",
        "    median = np.median(frequencies[idx])\n",
        "    weights[idx] = median / frequencies[idx]\n",
        "    weights[frequencies == 0] = 0.\n",
        "    return weights\n",
        "\n",
        "def camel_to_snake(name):\n",
        "    s = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
        "    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s).lower()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class SupConLoss(nn.Module):\n",
        "    \"\"\"Supervised Contrastive Learning: https://arxiv.org/pdf/2004.11362.pdf.\n",
        "    It also supports the unsupervised contrastive loss in SimCLR\"\"\"\n",
        "    def __init__(self, temperature=0.07, contrast_mode='all',\n",
        "                 base_temperature=0.07, device=None):\n",
        "        super(SupConLoss, self).__init__()\n",
        "        self.temperature = temperature\n",
        "        self.contrast_mode = contrast_mode\n",
        "        self.base_temperature = base_temperature\n",
        "        self.device=device\n",
        "\n",
        "    def forward(self, features, labels=None, mask=None, adv=False):\n",
        "        \"\"\"Compute loss for model. If both `labels` and `mask` are None,\n",
        "        it degenerates to SimCLR unsupervised loss:\n",
        "        https://arxiv.org/pdf/2002.05709.pdf\n",
        "\n",
        "        Args:\n",
        "            features: hidden vector of shape [bsz, n_views, ...].\n",
        "            labels: ground truth of shape [bsz].\n",
        "            mask: contrastive mask of shape [bsz, bsz], mask_{i,j}=1 if sample j\n",
        "                has the same class as sample i. Can be asymmetric.\n",
        "        Returns:\n",
        "            A loss scalar.\n",
        "        \"\"\"\n",
        "        if self.device is not None:\n",
        "            device = self.device\n",
        "        else:\n",
        "            device = (torch.device('cuda')\n",
        "                  if features.is_cuda\n",
        "                  else torch.device('cpu'))\n",
        "\n",
        "        if len(features.shape) < 3:\n",
        "            raise ValueError('`features` needs to be [bsz, n_views, ...],'\n",
        "                             'at least 3 dimensions are required')\n",
        "        if len(features.shape) > 3:\n",
        "            features = features.view(features.shape[0], features.shape[1], -1)\n",
        "\n",
        "        batch_size = features.shape[0]\n",
        "        if labels is not None and mask is not None:\n",
        "            raise ValueError('Cannot define both `labels` and `mask`')\n",
        "        elif labels is None and mask is None:\n",
        "            mask = torch.eye(batch_size, dtype=torch.float32).to(device)\n",
        "        elif labels is not None:\n",
        "            labels = labels.contiguous().view(-1, 1)\n",
        "            if labels.shape[0] != batch_size:\n",
        "                raise ValueError('Num of labels does not match num of features')\n",
        "            mask = torch.eq(labels, labels.T).float().to(device)\n",
        "        else:\n",
        "            mask = mask.float().to(device)\n",
        "\n",
        "        contrast_count = features.shape[1]\n",
        "        contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
        "        if self.contrast_mode == 'one':\n",
        "            anchor_feature = features[:, 0]\n",
        "            anchor_count = 1\n",
        "        elif self.contrast_mode == 'all':\n",
        "            anchor_feature = contrast_feature\n",
        "            anchor_count = contrast_count\n",
        "        else:\n",
        "            raise ValueError('Unknown mode: {}'.format(self.contrast_mode))\n",
        "\n",
        "        # compute logits\n",
        "        anchor_dot_contrast = torch.div(\n",
        "            torch.matmul(anchor_feature, contrast_feature.T),\n",
        "            self.temperature)\n",
        "        # for numerical stability\n",
        "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
        "        logits = anchor_dot_contrast - logits_max.detach()\n",
        "\n",
        "\n",
        "        # tile mask\n",
        "        mask = mask.repeat(anchor_count, contrast_count)\n",
        "        # mask-out self-contrast cases\n",
        "        logits_mask = torch.scatter(\n",
        "            torch.ones_like(mask),\n",
        "            1,\n",
        "            torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n",
        "            0\n",
        "        )\n",
        "        mask = mask * logits_mask\n",
        "        # compute log_prob\n",
        "        exp_logits = torch.exp(logits) * logits_mask\n",
        "        #log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n",
        "        if adv:\n",
        "            log_prob = torch.log( 1- exp_logits / (exp_logits.sum(1, keepdim=True)+1e-6) - 1e-6)\n",
        "        else:\n",
        "            log_prob = torch.log( exp_logits / (exp_logits.sum(1, keepdim=True)+1e-6) +1e-6)\n",
        "\n",
        "        # compute mean of log-likelihood over positive\n",
        "        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n",
        "\n",
        "        # loss\n",
        "        loss = - (self.temperature / self.base_temperature) * mean_log_prob_pos\n",
        "        loss = loss.view(anchor_count, batch_size).mean()\n",
        "\n",
        "        return loss\n",
        "\n",
        "if __name__=='__main__':\n",
        "    import torch.nn.functional as F\n",
        "    torch.manual_seed(0)\n",
        "    x = torch.randn(32, 2, 10)\n",
        "    x = F.normalize(x)\n",
        "    y = torch.randint(0, 10, [32])\n",
        "    loss_layer = SupConLoss()\n",
        "    loss = loss_layer(x, y)\n",
        "    print(loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnSdcDuiEj6W",
        "outputId": "01f9a1f7-d8fb-415d-85aa-f506d57757c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(13.6956)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b7OVyVwE69M",
        "outputId": "ab407f15-ab4e-43ea-9205-20a18ca9094a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Morphology(nn.Module):\n",
        "    '''\n",
        "    Base class for morpholigical operators\n",
        "    For now, only supports stride=1, dilation=1, kernel_size H==W, and padding='same'.\n",
        "    '''\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=5, soft_max=True, beta=15, type=None):\n",
        "        '''\n",
        "        in_channels: scalar\n",
        "        out_channels: scalar, the number of the morphological neure.\n",
        "        kernel_size: scalar, the spatial size of the morphological neure.\n",
        "        soft_max: bool, using the soft max rather the torch.max(), ref: Dense Morphological Networks: An Universal Function Approximator (Mondal et al. (2019)).\n",
        "        beta: scalar, used by soft_max.\n",
        "        type: str, dilation2d or erosion2d.\n",
        "        '''\n",
        "        super(Morphology, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.soft_max = soft_max\n",
        "        self.beta = beta\n",
        "        self.type = type\n",
        "\n",
        "        self.weight = nn.Parameter(torch.ones(out_channels, in_channels, kernel_size, kernel_size), requires_grad=True)\n",
        "        self.unfold = nn.Unfold(kernel_size, dilation=1, padding=0, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        x: tensor of shape (B,C,H,W)\n",
        "        '''\n",
        "        # padding\n",
        "        x = fixed_padding(x, self.kernel_size, dilation=1)\n",
        "\n",
        "        # unfold\n",
        "        x = self.unfold(x)  # (B, Cin*kH*kW, L), where L is the numbers of patches\n",
        "        x = x.unsqueeze(1)  # (B, 1, Cin*kH*kW, L)\n",
        "        L = x.size(-1)\n",
        "        L_sqrt = int(math.sqrt(L))\n",
        "\n",
        "        # erosion\n",
        "        weight = self.weight.view(self.out_channels, -1) # (Cout, Cin*kH*kW)\n",
        "        weight = weight.unsqueeze(0).unsqueeze(-1)  # (1, Cout, Cin*kH*kW, 1)\n",
        "\n",
        "        if self.type == 'erosion2d':\n",
        "            x = weight - x # (B, Cout, Cin*kH*kW, L)\n",
        "        elif self.type == 'dilation2d':\n",
        "            x = weight + x # (B, Cout, Cin*kH*kW, L)\n",
        "        else:\n",
        "            raise ValueError\n",
        "\n",
        "        if not self.soft_max:\n",
        "            x, _ = torch.max(x, dim=2, keepdim=False) # (B, Cout, L)\n",
        "        else:\n",
        "            x = torch.logsumexp(x*self.beta, dim=2, keepdim=False) / self.beta # (B, Cout, L)\n",
        "\n",
        "        if self.type == 'erosion2d':\n",
        "            x = -1 * x\n",
        "\n",
        "        # instead of fold, we use view to avoid copy\n",
        "        x = x.view(-1, self.out_channels, L_sqrt, L_sqrt)  # (B, Cout, L/2, L/2)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Dilation2d(Morphology):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=5, soft_max=True, beta=20):\n",
        "        super(Dilation2d, self).__init__(in_channels, out_channels, kernel_size, soft_max, beta, 'dilation2d')\n",
        "\n",
        "class Erosion2d(Morphology):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=5, soft_max=True, beta=20):\n",
        "        super(Erosion2d, self).__init__(in_channels, out_channels, kernel_size, soft_max, beta, 'erosion2d')\n",
        "\n",
        "def fixed_padding(inputs, kernel_size, dilation):\n",
        "    kernel_size_effective = kernel_size + (kernel_size - 1) * (dilation - 1)\n",
        "    pad_total = kernel_size_effective - 1\n",
        "    pad_beg = pad_total // 2\n",
        "    pad_end = pad_total - pad_beg\n",
        "    padded_inputs = F.pad(inputs, (pad_beg, pad_end, pad_beg, pad_end))\n",
        "    return padded_inputs"
      ],
      "metadata": {
        "id": "GbrWf2R8FVhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, inchannel, outchannel, num_classes, patch_size):\n",
        "        super(Discriminator, self).__init__()\n",
        "        dim = 512\n",
        "        self.patch_size = patch_size\n",
        "        self.inchannel = inchannel\n",
        "        self.conv1 = nn.Conv2d(inchannel, 64, kernel_size=3, stride=1, padding=0)\n",
        "        self.mp = nn.MaxPool2d(2)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=0)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.fc1 = nn.Linear(self._get_final_flattened_size(), dim)\n",
        "        self.relu3 = nn.ReLU(inplace=True)\n",
        "        self.fc2 = nn.Linear(dim, dim)\n",
        "        self.relu4 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.cls_head_src = nn.Linear(dim, num_classes)\n",
        "        self.p_mu = nn.Linear(dim, outchannel, nn.LeakyReLU())\n",
        "        self.pro_head = nn.Linear(dim, outchannel, nn.ReLU())\n",
        "\n",
        "    def _get_final_flattened_size(self):\n",
        "        with torch.no_grad():\n",
        "            x = torch.zeros((1, self.inchannel,\n",
        "                             self.patch_size, self.patch_size))\n",
        "            in_size = x.size(0)\n",
        "            out1 = self.mp(self.relu1(self.conv1(x)))\n",
        "            out2 = self.mp(self.relu2(self.conv2(out1)))\n",
        "            out2 = out2.view(in_size, -1)\n",
        "            w, h = out2.size()\n",
        "            fc_1 = w * h\n",
        "        return fc_1\n",
        "\n",
        "    def forward(self, x, mode='test'):\n",
        "\n",
        "        in_size = x.size(0)\n",
        "        out1 = self.mp(self.relu1(self.conv1(x)))\n",
        "        out2 = self.mp(self.relu2(self.conv2(out1)))\n",
        "        out2 = out2.view(in_size, -1)\n",
        "        out3 = self.relu3(self.fc1(out2))\n",
        "        out4 = self.relu4(self.fc2(out3))\n",
        "\n",
        "        if mode == 'test':\n",
        "            clss = self.cls_head_src(out4)\n",
        "            return clss\n",
        "        elif mode == 'train':\n",
        "            proj = F.normalize(self.pro_head(out4))\n",
        "            clss = self.cls_head_src(out4)\n",
        "\n",
        "            return clss, proj\n",
        "\n",
        "\n",
        "class MorphNet(nn.Module):\n",
        "    def __init__(self, inchannel):\n",
        "        super(MorphNet, self).__init__()\n",
        "        num = 1\n",
        "        kernel_size = 3\n",
        "        self.conv1 = nn.Conv2d(inchannel, num, kernel_size=1, stride=1, padding=0)\n",
        "        self.mp = nn.MaxPool2d(2)\n",
        "        self.Erosion2d_1=Erosion2d(num, num, kernel_size, soft_max=False)\n",
        "        self.Dilation2d_1=Dilation2d(num, num, kernel_size, soft_max=False)\n",
        "        self.Erosion2d_2=Erosion2d(num, num, kernel_size, soft_max=False)\n",
        "        self.Dilation2d_2=Dilation2d(num, num, kernel_size, soft_max=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = F.relu(self.conv1(x))\n",
        "        xop_2 = self.Dilation2d_1(self.Erosion2d_1(x))\n",
        "        xcl_2 = self.Erosion2d_2(self.Dilation2d_2(x))\n",
        "        x_top = x - xop_2\n",
        "        x_blk = xcl_2 - x\n",
        "        x_morph = torch.cat((x_top,x_blk,xop_2,xcl_2),1)\n",
        "\n",
        "        return x_morph"
      ],
      "metadata": {
        "id": "wEHTELHUFYTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SpaRandomization(nn.Module):\n",
        "    def __init__(self, num_features, eps=1e-5, device=0):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.norm = nn.InstanceNorm2d(num_features, affine=False)\n",
        "        self.alpha = nn.Parameter(torch.tensor(0.5), requires_grad=True).to(device)\n",
        "\n",
        "    def forward(self, x,):\n",
        "        N, C, H, W = x.size()\n",
        "        # x = self.norm(x)\n",
        "        if self.training:\n",
        "            x = x.view(N, C, -1)\n",
        "            mean = x.mean(-1, keepdim=True)\n",
        "            var = x.var(-1, keepdim=True)\n",
        "\n",
        "            x = (x - mean) / (var + self.eps).sqrt()\n",
        "\n",
        "            idx_swap = torch.randperm(N)\n",
        "            alpha = torch.rand(N, 1, 1)\n",
        "            mean = self.alpha * mean + (1 - self.alpha) * mean[idx_swap]\n",
        "            var = self.alpha * var + (1 - self.alpha) * var[idx_swap]\n",
        "\n",
        "            x = x * (var + self.eps).sqrt() + mean\n",
        "            x = x.view(N, C, H, W)\n",
        "\n",
        "        return x, idx_swap\n",
        "\n",
        "\n",
        "class SpeRandomization(nn.Module):\n",
        "    def __init__(self,num_features, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.norm = nn.InstanceNorm2d(num_features, affine=False)\n",
        "\n",
        "    def forward(self, x, idx_swap,y=None):\n",
        "        N, C, H, W = x.size()\n",
        "\n",
        "        if self.training:\n",
        "            x = x.view(N, C, -1)\n",
        "            mean = x.mean(1, keepdim=True)\n",
        "            var = x.var(1, keepdim=True)\n",
        "\n",
        "            x = (x - mean) / (var + self.eps).sqrt()\n",
        "            if y!= None:\n",
        "                for i in range(len(y.unique())):\n",
        "                    index= y==y.unique()[i]\n",
        "                    tmp, mean_tmp, var_tmp = x[index], mean[index], var[index]\n",
        "                    tmp = tmp[torch.randperm(tmp.size(0))].detach()\n",
        "                    tmp = tmp * (var_tmp + self.eps).sqrt() + mean_tmp\n",
        "                    x[index] = tmp\n",
        "            else:\n",
        "                # idx_swap = torch.randperm(N)\n",
        "                x = x[idx_swap].detach()\n",
        "\n",
        "                x = x * (var + self.eps).sqrt() + mean\n",
        "            x = x.view(N, C, H, W)\n",
        "        return x\n",
        "\n",
        "\n",
        "class AdaIN2d(nn.Module):\n",
        "    def __init__(self, style_dim, num_features):\n",
        "        super().__init__()\n",
        "        self.norm = nn.InstanceNorm2d(num_features, affine=False)\n",
        "        self.fc = nn.Linear(style_dim, num_features*2)\n",
        "    def forward(self, x, s):\n",
        "        h = self.fc(s)\n",
        "        h = h.view(h.size(0), h.size(1), 1, 1)\n",
        "        gamma, beta = torch.chunk(h, chunks=2, dim=1)\n",
        "        return (1 + gamma) * self.norm(x) + beta\n",
        "        #return (1+gamma)*(x)+beta\n",
        "\n",
        "class Reshape(nn.Module):\n",
        "    def __init__(self, *args):\n",
        "        super(Reshape, self).__init__()\n",
        "        self.shape = args\n",
        "    def forward(self, x):\n",
        "        return x.view((x.size(0),)+self.shape)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, n=16, kernelsize=3, imdim=3, imsize=[13, 13], zdim=10, device=0):\n",
        "        ''' w_ln 局部噪声权重\n",
        "        '''\n",
        "        super().__init__()\n",
        "        stride = (kernelsize-1)//2\n",
        "        self.zdim = zdim\n",
        "        self.imdim = imdim\n",
        "        self.imsize = imsize\n",
        "        self.device = device\n",
        "        num_morph = 4\n",
        "        self.Morphology = MorphNet(imdim)\n",
        "        self.adain2_morph = AdaIN2d(zdim, num_morph)\n",
        "\n",
        "        self.conv_spa1 = nn.Conv2d(imdim, 3, 1, 1)\n",
        "        self.conv_spa2 = nn.Conv2d(3, n, 1, 1)\n",
        "        self.conv_spe1 = nn.Conv2d(imdim, n, imsize[0], 1)\n",
        "        self.conv_spe2 = nn.ConvTranspose2d(n, n, imsize[0])\n",
        "        self.conv1 = nn.Conv2d(n+n+num_morph, n, kernelsize, 1, stride)\n",
        "        self.conv2 = nn.Conv2d(n, imdim, kernelsize, 1, stride)\n",
        "        self.speRandom = SpeRandomization(n)\n",
        "        self.spaRandom = SpaRandomization(3, device=device)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x_morph= self.Morphology(x)\n",
        "        z = torch.randn(len(x), self.zdim).to(self.device)\n",
        "        x_morph = self.adain2_morph(x_morph, z)\n",
        "\n",
        "        x_spa = F.relu(self.conv_spa1(x))\n",
        "        x_spe = F.relu(self.conv_spe1(x))\n",
        "        x_spa, idx_swap = self.spaRandom(x_spa)\n",
        "        x_spe = self.speRandom(x_spe,idx_swap)\n",
        "        x_spe = self.conv_spe2(x_spe)\n",
        "        x_spa = self.conv_spa2(x_spa)\n",
        "\n",
        "        x = F.relu(self.conv1(torch.cat((x_spa,x_spe,x_morph),1)))\n",
        "        x = torch.sigmoid(self.conv2(x))\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "iIoxZQ2OFf9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hyperx"
      ],
      "metadata": {
        "id": "82hHTSn4lHog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c1b120-7071-49cb-9a9c-547d9f8b8bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hyperx\n",
            "  Downloading hyperx-2024.1.9-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pythonnet>=3.0.1 (from hyperx)\n",
            "  Downloading pythonnet-3.0.3-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.0/291.0 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting clr-loader<0.3.0,>=0.2.6 (from pythonnet>=3.0.1->hyperx)\n",
            "  Downloading clr_loader-0.2.6-py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.13 in /usr/local/lib/python3.10/dist-packages (from clr-loader<0.3.0,>=0.2.6->pythonnet>=3.0.1->hyperx) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.13->clr-loader<0.3.0,>=0.2.6->pythonnet>=3.0.1->hyperx) (2.22)\n",
            "Installing collected packages: clr-loader, pythonnet, hyperx\n",
            "Successfully installed clr-loader-0.2.6 hyperx-2024.1.9 pythonnet-3.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "This file contains the PyTorch dataset for hyperspectral images and\n",
        "related helpers.\n",
        "\"\"\"\n",
        "!pip install spectral\n",
        "import spectral\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils\n",
        "import torch.utils.data\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from scipy.linalg import sqrtm\n",
        "try:\n",
        "    # Python 3\n",
        "    from urllib.request import urlretrieve\n",
        "except ImportError:\n",
        "    # Python 2\n",
        "    from urllib import urlretrieve\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "DATASETS_CONFIG = {\n",
        "        'Houston13': {\n",
        "            'img': 'Houston13.mat',\n",
        "            'gt': 'Houston13_7gt.mat',\n",
        "            },\n",
        "        'Houston18': {\n",
        "            'img': 'Houston18.mat',\n",
        "            'gt': 'Houston18_7gt.mat',\n",
        "            },\n",
        "        'paviaU': {\n",
        "            'img': 'paviaU.mat',\n",
        "            'gt': 'paviaU_7gt.mat',\n",
        "            },\n",
        "        'paviaC': {\n",
        "            'img': 'paviaC.mat',\n",
        "            'gt': 'paviaC_7gt.mat',\n",
        "            },\n",
        "    }\n",
        "\n",
        "try:\n",
        "    from custom_datasets import CUSTOM_DATASETS_CONFIG\n",
        "    DATASETS_CONFIG.update(CUSTOM_DATASETS_CONFIG)\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "class TqdmUpTo(tqdm):\n",
        "    \"\"\"Provides `update_to(n)` which uses `tqdm.update(delta_n)`.\"\"\"\n",
        "    def update_to(self, b=1, bsize=1, tsize=None):\n",
        "        \"\"\"\n",
        "        b  : int, optional\n",
        "            Number of blocks transferred so far [default: 1].\n",
        "        bsize  : int, optional\n",
        "            Size of each block (in tqdm units) [default: 1].\n",
        "        tsize  : int, optional\n",
        "            Total size (in tqdm units). If [default: None] remains unchanged.\n",
        "        \"\"\"\n",
        "        if tsize is not None:\n",
        "            self.total = tsize\n",
        "        self.update(b * bsize - self.n)  # will also set self.n = b * bsize\n",
        "\n",
        "\n",
        "def get_dataset(dataset_name, target_folder, datasets=DATASETS_CONFIG):\n",
        "    \"\"\" Gets the dataset specified by name and return the related components.\n",
        "    Args:\n",
        "        dataset_name: string with the name of the dataset\n",
        "        target_folder (optional): folder to store the datasets, defaults to ./\n",
        "        datasets (optional): dataset configuration dictionary, defaults to prebuilt one\n",
        "    Returns:\n",
        "        img: 3D hyperspectral image (WxHxB)\n",
        "        gt: 2D int array of labels\n",
        "        label_values: list of class names\n",
        "        ignored_labels: list of int classes to ignore\n",
        "        rgb_bands: int tuple that correspond to red, green and blue bands\n",
        "    \"\"\"\n",
        "    palette = None\n",
        "    print(datasets.keys())\n",
        "    if dataset_name not in datasets.keys():\n",
        "        raise ValueError(\"{} dataset is unknown.\".format(dataset_name))\n",
        "\n",
        "    dataset = datasets[dataset_name]\n",
        "\n",
        "    folder =  target_folder #+ datasets[dataset_name].get('folder', dataset_name + '/')\n",
        "    print(folder)\n",
        "\n",
        "    if dataset_name == 'Houston13':\n",
        "        # Load the image\n",
        "        img = h5py.File(folder + 'Houston13.mat', 'r')['ori_data'][:, :, :].transpose(1, 2, 0)\n",
        "        print(img.shape)\n",
        "        rgb_bands = [13,20,33]\n",
        "\n",
        "        gt = np.asarray(open_file(folder + 'Houston13_7gt.mat')['map'])\n",
        "        print(gt.shape)\n",
        "\n",
        "        label_values = [\"grass healthy\", \"grass stressed\", \"trees\",\n",
        "                        \"water\", \"residential buildings\",\n",
        "                        \"non-residential buildings\", \"road\"]\n",
        "\n",
        "        ignored_labels = [0]\n",
        "\n",
        "    elif dataset_name == 'Houston18':\n",
        "        # Load the image\n",
        "        img = h5py.File(folder + 'Houston18.mat', 'r')['ori_data'][:, :, :].transpose(1, 2, 0)\n",
        "        rgb_bands = [13,20,33]\n",
        "\n",
        "        #gt = np.asarray(open_file(folder + 'Houston18_7gt.mat')['map'])\n",
        "        gt=open_file(folder + 'Houston18_7gt.mat')['map']\n",
        "        label_values = [\"grass healthy\", \"grass stressed\", \"trees\",\n",
        "                        \"water\", \"residential buildings\",\n",
        "                        \"non-residential buildings\", \"road\"]\n",
        "\n",
        "        ignored_labels = [0]\n",
        "\n",
        "    elif dataset_name == 'paviaU':\n",
        "        # Load the image\n",
        "        img = h5py.File(folder + 'paviaU.mat', 'r')['ori_data'][:, :, :].transpose(1, 2, 0)\n",
        "\n",
        "        rgb_bands = [20,30,30]\n",
        "\n",
        "        gt = np.asarray(open_file(folder + 'paviaU_7gt.mat')['map'])\n",
        "\n",
        "        label_values = [\"tree\", \"asphalt\", \"brick\",\n",
        "                        \"bitumen\", \"shadow\", 'meadow', 'bare soil']\n",
        "\n",
        "        ignored_labels = [0]\n",
        "\n",
        "    elif dataset_name == 'paviaC':\n",
        "        h5py_kwargs = dict(swmr=False)\n",
        "\n",
        "        # Load the image\n",
        "        img = h5py.File(folder + 'paviaC.mat', 'r')['ori_data'][:, :, :].transpose(1, 2, 0)\n",
        "\n",
        "        rgb_bands = [20,30,30]\n",
        "\n",
        "        gt = np.asarray(open_file(folder + 'paviaC_7gt.mat')['map'])\n",
        "\n",
        "        label_values = [\"tree\", \"asphalt\", \"brick\",\n",
        "                        \"bitumen\", \"shadow\", 'meadow', 'bare soil']\n",
        "\n",
        "        ignored_labels = [0]\n",
        "    else:\n",
        "        # Custom dataset\n",
        "        img, gt, rgb_bands, ignored_labels, label_values, palette = CUSTOM_DATASETS_CONFIG[dataset_name]['loader'](folder)\n",
        "\n",
        "    # Filter NaN out\n",
        "    nan_mask = np.isnan(img.sum(axis=-1))\n",
        "    if np.count_nonzero(nan_mask) > 0:\n",
        "       print(\"Warning: NaN have been found in the data. It is preferable to remove them beforehand. Learning on NaN data is disabled.\")\n",
        "    img[nan_mask] = 0\n",
        "    gt[nan_mask] = 0\n",
        "    ignored_labels.append(0)\n",
        "\n",
        "    ignored_labels = list(set(ignored_labels))\n",
        "    # Normalization\n",
        "    img = np.asarray(img, dtype='float32')\n",
        "\n",
        "    m, n, d = img.shape[0], img.shape[1], img.shape[2]\n",
        "    img= img.reshape((m*n,-1))\n",
        "    img = img/img.max()\n",
        "    img_temp = np.sqrt(np.asarray((img**2).sum(1)))\n",
        "    img_temp = np.expand_dims(img_temp,axis=1)\n",
        "    img_temp = img_temp.repeat(d,axis=1)\n",
        "    img_temp[img_temp==0]=1\n",
        "    img = img/img_temp\n",
        "    img = np.reshape(img,(m,n,-1))\n",
        "\n",
        "    return img, gt, label_values, ignored_labels, rgb_bands, palette\n",
        "\n",
        "\n",
        "class HyperX(torch.utils.data.Dataset):\n",
        "    \"\"\" Generic class for a hyperspectral scene \"\"\"\n",
        "\n",
        "    def __init__(self, data, gt, transform=None, **hyperparams):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data: 3D hyperspectral image\n",
        "            gt: 2D array of labels\n",
        "            patch_size: int, size of the spatial neighbourhood\n",
        "            center_pixel: bool, set to True to consider only the label of the\n",
        "                          center pixel\n",
        "            data_augmentation: bool, set to True to perform random flips\n",
        "            supervision: 'full' or 'semi' supervised algorithms\n",
        "        \"\"\"\n",
        "        super(HyperX, self).__init__()\n",
        "        self.transform = transform\n",
        "        self.data = data\n",
        "        self.label = gt\n",
        "        self.patch_size = hyperparams['patch_size']\n",
        "        self.ignored_labels = set(hyperparams['ignored_labels'])\n",
        "        self.flip_augmentation = hyperparams['flip_augmentation']\n",
        "        self.radiation_augmentation = hyperparams['radiation_augmentation']\n",
        "        self.mixture_augmentation = hyperparams['mixture_augmentation']\n",
        "        self.center_pixel = hyperparams['center_pixel']\n",
        "        supervision = hyperparams['supervision']\n",
        "        # Fully supervised : use all pixels with label not ignored\n",
        "        if supervision == 'full':\n",
        "            mask = np.ones_like(gt)\n",
        "            for l in self.ignored_labels:\n",
        "                mask[gt == l] = 0\n",
        "        # Semi-supervised : use all pixels, except padding\n",
        "        elif supervision == 'semi':\n",
        "            mask = np.ones_like(gt)\n",
        "        x_pos, y_pos = np.nonzero(mask)\n",
        "        p = self.patch_size // 2\n",
        "        self.indices = np.array([(x,y) for x,y in zip(x_pos, y_pos) if x > p and x < data.shape[0] - p and y > p and y < data.shape[1] - p])\n",
        "        self.labels = [self.label[x,y] for x,y in self.indices]\n",
        "\n",
        "        state = np.random.get_state()\n",
        "        np.random.shuffle(self.indices)\n",
        "        np.random.set_state(state)\n",
        "        np.random.shuffle(self.labels)\n",
        "\n",
        "    @staticmethod\n",
        "    def flip(*arrays):\n",
        "        horizontal = np.random.random() > 0.5\n",
        "        vertical = np.random.random() > 0.5\n",
        "        if horizontal:\n",
        "            arrays = [np.fliplr(arr) for arr in arrays]\n",
        "        if vertical:\n",
        "            arrays = [np.flipud(arr) for arr in arrays]\n",
        "        return arrays\n",
        "\n",
        "    @staticmethod\n",
        "    def radiation_noise(data, alpha_range=(0.9, 1.1), beta=1/25):\n",
        "        alpha = np.random.uniform(*alpha_range)\n",
        "        noise = np.random.normal(loc=0., scale=1.0, size=data.shape)\n",
        "        return alpha * data + beta * noise\n",
        "\n",
        "    def mixture_noise(self, data, label, beta=1/25):\n",
        "        alpha1, alpha2 = np.random.uniform(0.01, 1., size=2)\n",
        "        noise = np.random.normal(loc=0., scale=1.0, size=data.shape)\n",
        "        data2 = np.zeros_like(data)\n",
        "        for  idx, value in np.ndenumerate(label):\n",
        "            if value not in self.ignored_labels:\n",
        "                l_indices = np.nonzero(self.labels == value)[0]\n",
        "                l_indice = np.random.choice(l_indices)\n",
        "                assert(self.labels[l_indice] == value)\n",
        "                x, y = self.indices[l_indice]\n",
        "                data2[idx] = self.data[x,y]\n",
        "        return (alpha1 * data + alpha2 * data2) / (alpha1 + alpha2) + beta * noise\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        x, y = self.indices[i]\n",
        "        x1, y1 = x - self.patch_size // 2, y - self.patch_size // 2\n",
        "        x2, y2 = x1 + self.patch_size, y1 + self.patch_size\n",
        "\n",
        "        data = self.data[x1:x2, y1:y2]\n",
        "        label = self.label[x1:x2, y1:y2]\n",
        "\n",
        "        if self.flip_augmentation and self.patch_size > 1 and np.random.random() < 0.5:\n",
        "            # Perform data augmentation (only on 2D patches)\n",
        "            data, label = self.flip(data, label)\n",
        "        if self.radiation_augmentation and np.random.random() < 0.5:\n",
        "                data = self.radiation_noise(data)\n",
        "        if self.mixture_augmentation and np.random.random() < 0.5:\n",
        "                data = self.mixture_noise(data, label)\n",
        "\n",
        "        # Copy the data into numpy arrays (PyTorch doesn't like numpy views)\n",
        "        data = np.asarray(np.copy(data).transpose((2, 0, 1)), dtype='float32')\n",
        "        label = np.asarray(np.copy(label), dtype='int64')\n",
        "\n",
        "        # Load the data into PyTorch tensors\n",
        "        data = torch.from_numpy(data)\n",
        "        label = torch.from_numpy(label)\n",
        "        # Extract the center label if needed\n",
        "        if self.center_pixel and self.patch_size > 1:\n",
        "            label = label[self.patch_size // 2, self.patch_size // 2]\n",
        "        # Remove unused dimensions when we work with invidual spectrums\n",
        "        elif self.patch_size == 1:\n",
        "            data = data[:, 0, 0]\n",
        "            label = label[0, 0]\n",
        "        else:\n",
        "            label = self.labels[i]\n",
        "\n",
        "        # Add a fourth dimension for 3D CNN\n",
        "        # if self.patch_size > 1:\n",
        "        #     # Make 4D data ((Batch x) Planes x Channels x Width x Height)\n",
        "        #     data = data.unsqueeze(0)\n",
        "        # plt.imshow(data[[10,23,23],:,:].permute(1,2,0))\n",
        "        # plt.show()\n",
        "        return data, label\n",
        "\n",
        "class data_prefetcher():\n",
        "    def __init__(self, loader):\n",
        "        self.loader = iter(loader)\n",
        "        self.stream = torch.cuda.Stream()\n",
        "        self.preload()\n",
        "\n",
        "    def preload(self):\n",
        "        try:\n",
        "            self.data, self.label = next(self.loader)\n",
        "\n",
        "        except StopIteration:\n",
        "            self.next_input = None\n",
        "\n",
        "            return\n",
        "        with torch.cuda.stream(self.stream):\n",
        "            self.data = self.data.cuda(non_blocking=True)\n",
        "            self.label = self.label.cuda(non_blocking=True)\n",
        "\n",
        "    def next(self):\n",
        "        torch.cuda.current_stream().wait_stream(self.stream)\n",
        "        data = self.data\n",
        "        label = self.label\n",
        "\n",
        "        self.preload()\n",
        "        return data, label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-dRPOPz2OM_",
        "outputId": "916c3906-c88e-4f1e-a702-d777f70d8f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spectral in /usr/local/lib/python3.10/dist-packages (0.23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from spectral) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.utils.data as data\n",
        "from tensorboardX import SummaryWriter\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Define parameters (replace with your desired values or interactive widgets)\n",
        "save_path = '/results/'\n",
        "data_path = '/content/drive/MyDrive/datasets/Houston/'\n",
        "source_name = 'Houston13'\n",
        "target_name = 'Houston18'\n",
        "gpu = 0  # Set to -1 for CPU, or use a GPU index if available\n",
        "patch_size = 13\n",
        "lr = 1e-3\n",
        "momentum = 0.9\n",
        "batch_size = 256\n",
        "pro_dim = 128\n",
        "test_stride = 1\n",
        "seed = 233\n",
        "l2_decay = 1e-4\n",
        "num_epoch = 500\n",
        "training_sample_ratio = 0.8\n",
        "re_ratio = 5\n",
        "max_epoch = 400\n",
        "log_interval = 40\n",
        "d_se = 64\n",
        "lambda_1 = 1.0\n",
        "lambda_2 = 1.0\n",
        "lr_scheduler = 'none'\n",
        "\n",
        "\n",
        "def evaluate(net, val_loader, gpu, tgt=False):\n",
        "    ps = []\n",
        "    ys = []\n",
        "    for i,(x1, y1) in enumerate(val_loader):\n",
        "        y1 = y1 - 1\n",
        "        with torch.no_grad():\n",
        "            x1 = x1.to(gpu)\n",
        "            p1 = net(x1)\n",
        "            p1 = p1.argmax(dim=1)\n",
        "            ps.append(p1.detach().cpu().numpy())\n",
        "            ys.append(y1.numpy())\n",
        "    ps = np.concatenate(ps)\n",
        "    ys = np.concatenate(ys)\n",
        "    acc = np.mean(ys==ps)*100\n",
        "    if tgt:\n",
        "        results = metrics(ps, ys, n_classes=ys.max()+1)\n",
        "        print(results['Confusion_matrix'],'\\n','TPR:', np.round(results['TPR']*100,2),'\\n', 'OA:', results['Accuracy'])\n",
        "    return acc\n",
        "\n",
        "\n",
        "def evaluate_tgt(cls_net, gpu, loader, modelpath):\n",
        "    saved_weight = torch.load(modelpath)\n",
        "    cls_net.load_state_dict(saved_weight['Discriminator'])\n",
        "    cls_net.eval()\n",
        "    teacc = evaluate(cls_net, loader, gpu, tgt=True)\n",
        "    return teacc\n",
        "\n",
        "def experiment():\n",
        "    settings = locals().copy()\n",
        "    print(settings)\n",
        "    hyperparams = {\n",
        "        'save_path': save_path,\n",
        "        'data_path': data_path,\n",
        "        'source_name': source_name,\n",
        "        'target_name': target_name,\n",
        "        'gpu': gpu,\n",
        "        'patch_size': patch_size,\n",
        "        'lr': lr,\n",
        "        'momentum': momentum,\n",
        "        'batch_size': batch_size,\n",
        "        'pro_dim': pro_dim,\n",
        "        'test_stride': test_stride,\n",
        "        'seed': seed,\n",
        "        'l2_decay': l2_decay,\n",
        "        'num_epoch': num_epoch,\n",
        "        'training_sample_ratio': training_sample_ratio,\n",
        "        're_ratio': re_ratio,\n",
        "        'max_epoch': max_epoch,\n",
        "        'log_interval': log_interval,\n",
        "        'd_se': d_se,\n",
        "        'lambda_1': lambda_1,\n",
        "        'lambda_2': lambda_2,\n",
        "        'lr_scheduler': lr_scheduler\n",
        "    }\n",
        "    print(hyperparams)\n",
        "    now_time = datetime.now()\n",
        "    time_str = datetime.strftime(now_time, '%m-%d_%H-%M-%S')\n",
        "    root = os.path.join(save_path, source_name + 'to' + target_name)\n",
        "    log_dir = os.path.join(root, str(lr) + '_dim' + str(pro_dim) +\n",
        "                           '_pt' + str(patch_size) + '_bs' + str(batch_size) + '_' + time_str)\n",
        "    if not os.path.exists(root):\n",
        "        os.makedirs(root)\n",
        "    if not os.path.exists(log_dir):\n",
        "        os.makedirs(log_dir)\n",
        "    writer = SummaryWriter(log_dir)\n",
        "    df = pd.DataFrame([hyperparams])\n",
        "    df.to_csv(os.path.join(log_dir,'params.txt'))\n",
        "    seed_worker(seed)\n",
        "    img_src, gt_src, LABEL_VALUES_src, IGNORED_LABELS, RGB_BANDS, palette = get_dataset(source_name, data_path)\n",
        "    img_tar, gt_tar, LABEL_VALUES_tar, IGNORED_LABELS, RGB_BANDS, palette = get_dataset(target_name, data_path)\n",
        "    sample_num_src = len(np.nonzero(gt_src)[0])\n",
        "    sample_num_tar = len(np.nonzero(gt_tar)[0])\n",
        "\n",
        "    tmp = training_sample_ratio * re_ratio * sample_num_src / sample_num_tar\n",
        "    num_classes = gt_src.max()\n",
        "    N_BANDS = img_src.shape[-1]\n",
        "    hyperparams.update({'n_classes': num_classes, 'n_bands': N_BANDS, 'ignored_labels': IGNORED_LABELS,\n",
        "                        'device': gpu, 'center_pixel': None, 'supervision': 'full'})\n",
        "\n",
        "    r = int(patch_size / 2) + 1\n",
        "    img_src = np.pad(img_src, ((r, r), (r, r), (0, 0)), 'symmetric')\n",
        "    img_tar = np.pad(img_tar, ((r, r), (r, r), (0, 0)), 'symmetric')\n",
        "    gt_src = np.pad(gt_src, ((r, r), (r, r)), 'constant', constant_values=(0, 0))\n",
        "    gt_tar = np.pad(gt_tar, ((r, r), (r, r)), 'constant', constant_values=(0, 0))\n",
        "\n",
        "    train_gt_src, val_gt_src, _, _ = sample_gt(gt_src, training_sample_ratio, mode='random')\n",
        "    test_gt_tar, _, _, _ = sample_gt(gt_tar, 1, mode='random')\n",
        "    img_src_con, train_gt_src_con = img_src, train_gt_src\n",
        "    val_gt_src_con = val_gt_src\n",
        "    if tmp < 1:\n",
        "        for i in range(re_ratio - 1):\n",
        "            img_src_con = np.concatenate((img_src_con, img_src))\n",
        "            train_gt_src_con = np.concatenate((train_gt_src_con, train_gt_src))\n",
        "            val_gt_src_con = np.concatenate((val_gt_src_con, val_gt_src))\n",
        "\n",
        "    hyperparams_train = hyperparams.copy()\n",
        "    g = torch.Generator()\n",
        "    g.manual_seed(seed)\n",
        "    train_dataset = HyperX(img_src_con, train_gt_src_con, **hyperparams_train)\n",
        "    train_loader = data.DataLoader(train_dataset,\n",
        "                                    batch_size=hyperparams['batch_size'],\n",
        "                                    pin_memory=True,\n",
        "                                    worker_init_fn=seed_worker,\n",
        "                                    generator=g,\n",
        "                                    shuffle=True,)\n",
        "    val_dataset = HyperX(img_src_con, val_gt_src_con, **hyperparams)\n",
        "    val_loader = data.DataLoader(val_dataset,\n",
        "                                    pin_memory=True,\n",
        "                                    batch_size=hyperparams['batch_size'])\n",
        "    test_dataset = HyperX(img_tar, test_gt_tar, **hyperparams)\n",
        "    test_loader = data.DataLoader(test_dataset,\n",
        "                                    pin_memory=True,\n",
        "                                    worker_init_fn=seed_worker,\n",
        "                                    generator=g,\n",
        "                                    batch_size=hyperparams['batch_size'])\n",
        "    imsize = [hyperparams['patch_size'], hyperparams['patch_size']]\n",
        "\n",
        "    D_net = discriminator.Discriminator(inchannel=N_BANDS, outchannel=args.pro_dim, num_classes=num_classes,\n",
        "                                        patch_size=hyperparams['patch_size']).to(gpu)\n",
        "    D_opt = optim.Adam(D_net.parameters(), lr=lr)\n",
        "    G_net = generator.Generator(n=d_se, imdim=N_BANDS, imsize=imsize, zdim=10, device=gpu).to(gpu)\n",
        "    G_opt = optim.Adam(G_net.parameters(), lr=lr)\n",
        "    cls_criterion = nn.CrossEntropyLoss()\n",
        "    con_criterion = SupConLoss(device=gpu)\n",
        "\n",
        "    best_acc = 0\n",
        "    taracc, taracc_list = 0, []\n",
        "    for epoch in range(1,max_epoch+1):\n",
        "\n",
        "        t1 = time.time()\n",
        "        loss_list = []\n",
        "        D_net.train()\n",
        "        for i, (x, y) in enumerate(train_loader):\n",
        "            x, y = x.to(gpu), y.to(gpu)\n",
        "            y = y - 1\n",
        "            with torch.no_grad():\n",
        "                x_ED = G_net(x)\n",
        "            rand = torch.nn.init.uniform_(torch.empty(len(x), 1, 1, 1)).to(gpu) # Uniform distribution\n",
        "            x_ID = rand*x + (1-rand)*x_ED\n",
        "\n",
        "            x_tgt = G_net(x)\n",
        "            x2_tgt = G_net(x)\n",
        "            p_SD, z_SD = D_net(x, mode='train')\n",
        "            p_ED, z_ED = D_net(x_ED, mode='train')\n",
        "            p_ID, z_ID = D_net(x_ID, mode='train')\n",
        "            zsrc = torch.cat([z_SD.unsqueeze(1), z_ED.unsqueeze(1), z_ID.unsqueeze(1)], dim=1)\n",
        "            src_cls_loss = cls_criterion(p_SD, y.long()) + cls_criterion(p_ED, y.long()) + cls_criterion(p_ID, y.long())\n",
        "            p_tgt, z_tgt = D_net(x_tgt, mode='train')\n",
        "            tgt_cls_loss = cls_criterion(p_tgt, y.long())\n",
        "\n",
        "            zall = torch.cat([z_tgt.unsqueeze(1), zsrc], dim=1)\n",
        "            con_loss = con_criterion(zall, y, adv=False)\n",
        "            loss = src_cls_loss + lambda_1*con_loss + tgt_cls_loss\n",
        "            D_opt.zero_grad()\n",
        "            loss.backward(retain_graph=True)\n",
        "\n",
        "            num_adv = y.unique().size()\n",
        "            zsrc_con = torch.cat([z_tgt.unsqueeze(1), z_ED.unsqueeze(1), z_ID.unsqueeze(1)], dim=1)\n",
        "            con_loss_adv = 0\n",
        "            idx_1 = np.random.randint(0, zsrc.size(1))\n",
        "\n",
        "            for i,id in enumerate(y.unique()):\n",
        "                mask = y==y.unique()[i]\n",
        "                z_SD_i, zsrc_i = z_SD[mask], zsrc_con[mask]\n",
        "                y_i = torch.cat([torch.zeros(z_SD_i.shape[0]),torch.ones(z_SD_i.shape[0])])\n",
        "                zall = torch.cat([z_SD_i.unsqueeze(1), zsrc_i[:,idx_1:idx_1+1]], dim=0)\n",
        "                if y_i.size()[0] > 2:\n",
        "                    con_loss_adv += con_criterion(zall, y_i)\n",
        "            con_loss_adv = con_loss_adv/y.unique().shape[0]\n",
        "\n",
        "            loss = tgt_cls_loss + lambda_2*con_loss_adv\n",
        "            G_opt.zero_grad()\n",
        "            loss.backward()\n",
        "            D_opt.step()\n",
        "            G_opt.step()\n",
        "\n",
        "            loss_list.append([src_cls_loss.item(), tgt_cls_loss.item(), con_loss.item(), con_loss_adv.item()])\n",
        "        src_cls_loss, tgt_cls_loss, con_loss, con_loss_adv = np.mean(loss_list, 0)\n",
        "\n",
        "        D_net.eval()\n",
        "        teacc = evaluate(D_net, val_loader, gpu)\n",
        "        if best_acc < teacc:\n",
        "            best_acc = teacc\n",
        "            torch.save({'Discriminator':D_net.state_dict()}, os.path.join(log_dir, f'best.pkl'))\n",
        "        t2 = time.time()\n",
        "\n",
        "        print(f'epoch {epoch}, train {len(train_loader.dataset)}, time {t2-t1:.2f}, src_cls {src_cls_loss:.4f} tgt_cls {tgt_cls_loss:.4f} con {con_loss:.4f} con_adv {con_loss_adv:.4f} /// val {len(val_loader.dataset)}, teacc {teacc:2.2f}')\n",
        "        writer.add_scalar('src_cls_loss', src_cls_loss, epoch)\n",
        "        writer.add_scalar('tgt_cls_loss', tgt_cls_loss, epoch)\n",
        "        writer.add_scalar('con_loss', con_loss, epoch)\n",
        "        writer.add_scalar('con_loss_adv', con_loss_adv, epoch)\n",
        "        writer.add_scalar('teacc', teacc, epoch)\n",
        "\n",
        "        if epoch % log_interval == 0:\n",
        "            pklpath = f'{log_dir}/best.pkl'\n",
        "            taracc = evaluate_tgt(D_net, gpu, test_loader, pklpath)\n",
        "            taracc_list.append(round(taracc,2))\n",
        "            print(f'load pth, target sample number {len(test_loader.dataset)}, max taracc {max(taracc_list):2.2f}')\n",
        "    writer.close()\n",
        "\n",
        "if __name__=='__main__':\n",
        "    experiment()\n",
        "\n"
      ],
      "metadata": {
        "id": "9UomdIsq8Gtk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}